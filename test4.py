# -*- coding: utf-8 -*-
"""test4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15-F8nGiBbnAZHhBXCX9gmPtju8akGmjC
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

! pip install tensorflow_addons
! pip install scikeras[tensorflow]
! pip install tensorflow_ranking
# !pip3 uninstall keras-nightly
# !pip3 uninstall -y tensorflow
# !pip3 install keras==2.1.6
# !pip3 install tensorflow==1.15.0
# !pip3 install h5py==2.10.0

! pip install --upgrade albumentations
! pip install --upgrade opencv-python

! pip install gradio

#! pip install tensorflow==2.10

!pip list

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Data Reading

import os, datetime
from glob import glob
from PIL import Image
import joblib
# Data Processing

import numpy as np
import pandas as pd
import cv2
import random
import albumentations as A

# Data Analysis

import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns

# Data Modeling & Model Evaluation

from sklearn.model_selection import train_test_split
from sklearn.metrics import *
from keras.preprocessing import image
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img
from tensorflow. keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
import tensorflow as tf
import tensorflow_ranking as tfr
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score

# Grad-CAM

import keras
import matplotlib.cm as cm


from numpy.random import seed
seed(0)
import tensorflow as tf
tf.random.set_seed(0)

# load the TensorBoard notebook extension
# %load_ext tensorboard

#GUI
import gradio as gr

from google.colab import drive

drive.mount('/content/drive')

levels = ['Meat_Fresh', 'Meat_Spoiled']
path = 'drive/MyDrive/kampus/datasettrain/'
data_dir = os.path.join(path)
print(data_dir)

data = []

for id, level in enumerate(levels):
    for file in os.listdir(os.path.join(data_dir, level)):
        data.append(['{}/{}'.format(level, file), level])

data = pd.DataFrame(data, columns = ['image_file', 'beef_result'])


data['path'] = path +  + data['image_file']
data['beef_result'] = data['beef_result'].map({'Meat_Fresh': 'Meat_Fresh',
                                                 'Meat_Spoiled': 'Meat_Spoiled'})

data.head()

data['beef_result'].unique()

print('Number of Duplicated Samples: %d'%(data.duplicated().sum()))
print('Number of Total Samples: %d'%(data.isnull().value_counts()))

df = pd.DataFrame()
df['beef_result'] = ['Meat_Fresh','Meat_Spoiled']
df['Count'] = [len(data[data['beef_result'] == 'Meat_Fresh']), len(data[data['beef_result'] == 'Meat_Spoiled'])]
df = df.sort_values(by = ['Count'], ascending = False)

fig = px.bar(df, x = 'beef_result', y = 'Count',
             color = "beef_result", text_auto='', width = 600,
             color_discrete_sequence = ["blue", "green", "red"],
             template = 'plotly_dark')

fig.update_xaxes(showgrid = False)
fig.update_yaxes(showgrid = False)
fig.update_traces(textfont_size = 12, textangle = 0, textposition = "outside", cliponaxis = False)

fig.show()

data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((299,299))))
data.head()

from google.colab.patches import cv2_imshow
img = cv2.imread(data['path'][0], cv2.IMREAD_UNCHANGED)
label = 0 if data['beef_result'][0] == "Meat_Fresh" else 1
cv2_imshow(img)
print(img.shape, label)

# train_datagen = ImageDataGenerator(
#         rotation_range=20,
#         zoom_range=0.15,
#         width_shift_range=0.2,
#         height_shift_range=0.2,
#         shear_range=0.15,
#         horizontal_flip=True,
#         fill_mode="nearest")

# test_datagen = ImageDataGenerator()

train_datagen = ImageDataGenerator(
   rotation_range=20,
   zoom_range=0.15,
   width_shift_range=0.2,
   height_shift_range=0.2,
   shear_range=0.15,
   horizontal_flip=True,
   brightness_range=[0.8, 1.2],


   fill_mode="nearest")

test_datagen = ImageDataGenerator()
# # ...

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(a[i].astype('uint8'))
    label_index = np.argmax(labels[i])
    plt.title(class_labels[label_index])
    plt.axis('off')
plt.tight_layout()
plt.show()

print(test_datagen,data)

all_data = []

# Storing images and their labels into a list for further Train Test split

for i in range(len(data)):
    image = cv2.imread(data['path'][i])
    image = cv2.resize(image, (299, 299))
    label = 0 if data['beef_result'][i] == "Meat_Fresh" else 1
    all_data.append([image, label])

x = []
y = []

for image, label in all_data:
    x.append(image)
    y.append(label)

# Converting to Numpy Array
x = np.array(x, dtype=object)
y = np.array(y, dtype=object)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)
classes_num = 2 #jumlah class
y_train = tf.keras.utils.to_categorical(y_train , classes_num)
y_test = tf.keras.utils.to_categorical(y_test , classes_num )

y_test_arg = np.argmax(y_test,axis=1)
y_train_arg = np.argmax(y_train, axis=1)

INPUT_SHAPE = (299, 299, 3)
N_CLASSES = classes_num

# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, y_test_arg.shape, y_train_arg.shape)

# batch_size = 15
# train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)
# test_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Convolution2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose
from tensorflow.keras.layers import Flatten, MaxPooling2D, AveragePooling2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization
from tensorflow.keras.layers import concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU
from keras import regularizers
from keras import initializers
import tensorflow.keras.backend as K

"""INCEPTIONV4"""

def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1,
1)):

 x = keras.layers.Conv2D(filters, (num_row,
num_col),strides=strides,padding=padding)(x)
 x = keras.layers.BatchNormalization(axis=3, scale=False)(x)
 x = keras.layers.Activation('relu')(x)
 return x

def block_inception_A(input):
 A_1 = conv2d_bn(input, 96, 1, 1)
 A_2 = conv2d_bn(input, 64, 1, 1)
 A_2 = conv2d_bn(A_2, 96, 3, 3)
 A_3 = conv2d_bn(input, 64, 1, 1)
 A_3 = conv2d_bn(A_3, 96, 3, 3)
 A_3 = conv2d_bn(A_3, 96, 3, 3)

 A_4 = AveragePooling2D((3, 3), strides=(1, 1),
padding="same")(input)
 A_4 = conv2d_bn(A_4, 96, 1, 1)
 A = concatenate([A_1, A_2, A_3, A_4], axis = channel_axis)
 return A

def block_inception_B(input):
 B_1 = conv2d_bn(input, 384, 1, 1)

 B_2 = conv2d_bn(input, 192, 1, 1)
 B_2 = conv2d_bn(B_2, 224, 1, 7)
 B_2 = conv2d_bn(B_2, 256, 1, 7)

 B_3 = conv2d_bn(input, 192, 1, 1)
 B_3 = conv2d_bn(B_3, 192, 1, 7)
 B_3 = conv2d_bn(B_3, 224, 7, 1)
 B_3 = conv2d_bn(B_3, 224, 1, 7)
 B_3 = conv2d_bn(B_3, 256, 7, 1)

 B_4 = AveragePooling2D((3, 3), strides=(1, 1),
padding="same")(input)
 B_4 = conv2d_bn(B_4, 128, 1, 1)
 B = concatenate([B_1, B_2, B_3, B_4], axis= channel_axis)
 return B

def block_inception_C(input):
 C_1 = conv2d_bn(input, 256, 1, 1)

 C_2 = conv2d_bn(input, 384, 1, 1)
 C_21 = conv2d_bn(C_2, 256, 1, 3)
 C_22 = conv2d_bn(C_2, 256, 3, 1)
 C_2 = concatenate([C_21, C_22], axis=channel_axis)

 C_3 = conv2d_bn(input, 384, 1, 1)
 C_3 = conv2d_bn(C_3, 448, 1, 3)
 C_3 = conv2d_bn(C_3, 512, 3, 1)
 C_31 = conv2d_bn(C_3, 256, 1, 3)
 C_32 = conv2d_bn(C_3, 256, 3, 1)
 C_3 = concatenate([C_31, C_32], axis=channel_axis)

 C_4 = AveragePooling2D((3, 3), strides=(1, 1),
padding="same")(input)
 C_4 = conv2d_bn(C_4, 256, 1, 1)
 C = concatenate([C_1, C_2, C_3, C_4], axis=channel_axis)
 return C

def block_reduction_a(input):
 R_1 = conv2d_bn(input, 384, 3, 3, strides=(2, 2),
padding='valid')

 R_2 = conv2d_bn(input, 192, 1, 1)
 R_2 = conv2d_bn(R_2, 224, 3, 3)
 R_2 = conv2d_bn(R_2, 256, 3, 3, strides = (2, 2),
padding='valid')

 R_3 = MaxPooling2D((3, 3), strides=(2, 2),
padding="valid")(input)
 R = concatenate([R_1, R_2, R_3], axis=channel_axis)
 return R

def block_reduction_b(input):
 R_1 = conv2d_bn(input, 192, 1, 1)
 R_1 = conv2d_bn(input, 192, 3, 3, strides=(2, 2),
padding='valid')

 R_2 = conv2d_bn(input, 256, 1, 1)
 R_2 = conv2d_bn(R_2, 256, 1, 7)
 R_2 = conv2d_bn(R_2, 320, 7, 1)
 R_2 = conv2d_bn(R_2, 320, 3, 3, strides = (2, 2),
padding='valid')
 R_3 = MaxPooling2D((3, 3), strides=(2, 2),
padding="valid")(input)
 R = concatenate([R_1, R_2, R_3], axis=channel_axis)
 return R

img_input = keras.Input(shape=(299, 299, 3))

channel_axis=3
classes=2

net = conv2d_bn(img_input, 32, 3, 3, strides=(2,2), padding='valid')
net = conv2d_bn(net, 32, 3, 3, padding='valid')
net = conv2d_bn(net, 64, 3, 3)

branch_0 = MaxPooling2D((3,3), strides=(2, 2), padding='valid')(net)
branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2, 2), padding='valid')
net = concatenate([branch_0, branch_1], axis= channel_axis)

branch_0 = conv2d_bn(net, 64, 1, 1)
branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')

branch_1 = conv2d_bn(net, 64, 1, 1)
branch_1 = conv2d_bn(branch_1, 64, 7, 1)
branch_1 = conv2d_bn(branch_1, 64, 1, 7)
branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')

net = concatenate(([branch_0, branch_1]), axis=channel_axis)
branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')
branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)

net = concatenate([branch_0, branch_1], axis=channel_axis)

net = block_inception_A(net)
net = block_inception_A(net)
net = block_inception_A(net)
net = block_inception_A(net)

net = block_reduction_a(net)

net = block_inception_B(net)
net = block_inception_B(net)
net = block_inception_B(net)
net = block_inception_B(net)
net = block_inception_B(net)
net = block_inception_B(net)
net = block_inception_B(net)

net = block_reduction_b(net)

net = block_inception_C(net)
net = block_inception_C(net)
net = block_inception_C(net)

net = keras.layers.GlobalAveragePooling2D(name='avg_pool')(net)
shape=(None, 2048)
#net = AveragePooling2D((8, 8), padding = 'valid')(net)
net = Dropout(0.8)(net)
net = keras.layers.Dense(2, activation='softmax',
name='predictions')(net) #shape=(None, 1000)

from sklearn.metrics import roc_auc_score
#from keras.utils import np_utils
from keras.utils import to_categorical
#Create model
inputs = img_input
batch_size = 15
train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)
test_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)
model = keras.Model(inputs, net, name='inception_v4')
model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),

           loss = [tf.keras.losses.CategoricalCrossentropy(from_logits = False)],
           metrics = ['accuracy',
                      tfr.keras.metrics.MeanAveragePrecisionMetric(topn=N_CLASSES),
                      tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=N_CLASSES)])
model.summary()

"""TRAIN"""

#model_checkpoint
mc = ModelCheckpoint('drive/MyDrive/Colab Notebooks/Model/inceptionV4_RMSprop_model100_checkpoint.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)
logdir = os.path.join("drive/MyDrive/Colab Notebooks/Model/inceptionV4_Rmsprop_model100/logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
x_train = np.asarray(x_train).astype(np.float32)
y_train = np.asarray(y_train).astype(np.float32)

history = model.fit(
    train_generator,
    validation_data=test_generator,
    steps_per_epoch=len(x_train) // batch_size,
    epochs=10,
    callbacks=[mc, tensorboard_callback]
)

x_test = np.asarray(x_test).astype(np.float32)
y_test = np.asarray(y_test).astype(np.float32)

test_evaluation = model.evaluate(x_test, y_test)
print(f"Test Accuracy using Inception V4: {test_evaluation[1] * 100:.2f}%")

train_evaluation = model.evaluate(x_train, y_train)
print(f"Train Accuracy using Inception V4: {train_evaluation[1] * 100:.2f}%")

score = model.evaluate(x_test, y_test, verbose=0)
score[0]

print(y_test.shape)
print(y_test)

y_predicted = model.predict(x_test)
# y_predicted = y_predicted.flatten()
# y_predicted.reshape((1037))
print(y_predicted.shape)

# y_test = np_utils.to_categorical(encoded_Y_test)
print(y_test.shape)

y_predicted = y_predicted.argmax(axis=1)

y_test = y_test.argmax(axis=1)

y_predicted = np.where(y_predicted > 0.5, 1, 0)
y_predicted

# y_test = y_test.flatten()
print(y_test.shape)
# y_predicted = y_predicted.flatten()
print(y_predicted.shape)

cm = confusion_matrix(y_test, y_predicted)
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

print(classification_report(y_test, y_predicted))

plt.style.use('ggplot')

def plot_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    x = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(x, acc, 'b', label='Training acc')
    plt.plot(x, val_acc, 'r', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(x, loss, 'b', label='Training loss')
    plt.plot(x, val_loss, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

plot_history(history)

model.save('drive/MyDrive/Colab Notebooks/Model/inceptionV4RMSprop_0,0001_100_15_model100.h5')

new_model =  tf.keras.models.load_model("/content/drive/My Drive/Colab Notebooks/Model/inceptionV4RMSprop_0,0001_100_15_model100.h5")